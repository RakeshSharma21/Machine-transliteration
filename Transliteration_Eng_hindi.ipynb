{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 8741,
     "status": "ok",
     "timestamp": 1648216618900,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "gScySlJE_gJO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Instantiates the device to be used as GPU/CPU based on availability\n",
    "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0ys6J4JGP8g"
   },
   "source": [
    "Connecting to google drive for accessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49190,
     "status": "ok",
     "timestamp": 1648216668075,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "9V4LDJAwI37h",
    "outputId": "eed4da15-b77d-4ee4-a408-88e8c5342371"
   },
   "outputs": [],
   "source": [
    "# Load the Drive helper and mount\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKGzyl8bGlei"
   },
   "source": [
    "Since we are solving this problem at character level , hence creating vocal for english and hindi based upon the alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1648216668076,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "nUIajP2ZJF6Y",
    "outputId": "6fc4c39e-7c51-48a8-cd2f-1597171aca8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
     ]
    }
   ],
   "source": [
    "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "pad_char = '-PAD-'\n",
    "\n",
    "eng_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "    eng_alpha2index[alpha] = index+1\n",
    "\n",
    "print(eng_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1648216668076,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "vtSFnv10JezL",
    "outputId": "6650fade-aa86-4acf-ab0e-c13631847674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
     ]
    }
   ],
   "source": [
    "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
    "\n",
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "\n",
    "hindi_alpha2index = {pad_char: 0}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "    hindi_alpha2index[alpha] = index+1\n",
    "\n",
    "print(hindi_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1648216668077,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "TU2TCShc8jit",
    "outputId": "7f184165-4c3d-44e5-c27e-f74ea3b47226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ऀ': 0, 'ँ': 1, 'ं': 2, 'ः': 3, 'ऄ': 4, 'अ': 5, 'आ': 6, 'इ': 7, 'ई': 8, 'उ': 9, 'ऊ': 10, 'ऋ': 11, 'ऌ': 12, 'ऍ': 13, 'ऎ': 14, 'ए': 15, 'ऐ': 16, 'ऑ': 17, 'ऒ': 18, 'ओ': 19, 'औ': 20, 'क': 21, 'ख': 22, 'ग': 23, 'घ': 24, 'ङ': 25, 'च': 26, 'छ': 27, 'ज': 28, 'झ': 29, 'ञ': 30, 'ट': 31, 'ठ': 32, 'ड': 33, 'ढ': 34, 'ण': 35, 'त': 36, 'थ': 37, 'द': 38, 'ध': 39, 'न': 40, 'ऩ': 41, 'प': 42, 'फ': 43, 'ब': 44, 'भ': 45, 'म': 46, 'य': 47, 'र': 48, 'ऱ': 49, 'ल': 50, 'ळ': 51, 'ऴ': 52, 'व': 53, 'श': 54, 'ष': 55, 'स': 56, 'ह': 57, 'ऺ': 58, 'ऻ': 59, '़': 60, 'ऽ': 61, 'ा': 62, 'ि': 63, 'ी': 64, 'ु': 65, 'ू': 66, 'ृ': 67, 'ॄ': 68, 'ॅ': 69, 'ॆ': 70, 'े': 71, 'ै': 72, 'ॉ': 73, 'ॊ': 74, 'ो': 75, 'ौ': 76, '्': 77, 'ॎ': 78, 'ॏ': 79, 'ॐ': 80, '॑': 81, '॒': 82, '॓': 83, '॔': 84, 'ॕ': 85, 'ॖ': 86, 'ॗ': 87, 'क़': 88, 'ख़': 89, 'ग़': 90, 'ज़': 91, 'ड़': 92, 'ढ़': 93, 'फ़': 94, 'य़': 95, 'ॠ': 96, 'ॡ': 97, 'ॢ': 98, 'ॣ': 99, '।': 100, '॥': 101, '०': 102, '१': 103, '२': 104, '३': 105, '४': 106, '५': 107, '६': 108, '७': 109, '८': 110, '९': 111, '॰': 112, 'ॱ': 113, 'ॲ': 114, 'ॳ': 115, 'ॴ': 116, 'ॵ': 117, 'ॶ': 118, 'ॷ': 119, 'ॸ': 120, 'ॹ': 121, 'ॺ': 122, 'ॻ': 123, 'ॼ': 124, 'ॽ': 125, 'ॾ': 126, 'ॿ': 127}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "hindi_alphabet_size = len(hindi_alphabets)\n",
    "\n",
    "hindi_alpha2index_r = {}\n",
    "for index, alpha in enumerate(hindi_alphabets):\n",
    "    hindi_alpha2index_r[alpha] = index\n",
    "\n",
    "print(hindi_alpha2index_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648216668077,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "zkTI_U7t8w_x",
    "outputId": "ac9b47f3-c7a4-4e91-ef9b-9b21fa938356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "pad_char = '-PAD-'\n",
    "\n",
    "eng_alpha2index_r = {}\n",
    "for index, alpha in enumerate(eng_alphabets):\n",
    "    eng_alpha2index_r[alpha] = index\n",
    "\n",
    "print(eng_alpha2index_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648216668078,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "pCnhA7icQcld",
    "outputId": "1684ddc7-babe-40cf-908d-d7887ef09058"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hindi_alpha2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXcRqxfOGoKD"
   },
   "source": [
    "Methods to clean the english and hindi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648216673352,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "WxDbFzYLJqqq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
    "\n",
    "# Remove all English non-letters\n",
    "def cleanEnglishVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
    "    line = non_eng_letters_regex.sub('', line)\n",
    "    return line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648216673838,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "PBA3Im6gJjuH"
   },
   "outputs": [],
   "source": [
    "# Remove all Hindi non-letters\n",
    "def cleanHindiVocab(line):\n",
    "    line = line.replace('-', ' ').replace(',', ' ')\n",
    "    cleaned_line = ''\n",
    "    for char in line:\n",
    "        if char in hindi_alpha2index or char == ' ':\n",
    "            cleaned_line += char\n",
    "    return cleaned_line.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqcqwUD-Gtrh"
   },
   "source": [
    "Methods to convert hindi and english words into tensors based upon the characters in the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648216674646,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "JAXyH5onZiI7"
   },
   "outputs": [],
   "source": [
    "def eng_word_to_tensor(word, letter2index, device = 'cpu'):\n",
    "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        rep[letter_index][0][pos] = 1\n",
    "    pad_pos = letter2index[pad_char]\n",
    "    rep[letter_index+1][0][pad_pos] = 1\n",
    "    return rep\n",
    "\n",
    "def hindi_word_to_tensor(word, letter2index, device = 'cpu'):\n",
    "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        gt_rep[letter_index][0] = pos\n",
    "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
    "    return gt_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648216674648,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "DjPRFtC69CB_"
   },
   "outputs": [],
   "source": [
    "def eng_word_to_tensor_r(word, letter2index, device = 'cpu'):\n",
    "    rep = torch.zeros(len(word), 1, len(letter2index)).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        rep[letter_index][0][pos] = 1\n",
    "    # pad_pos = letter2index[pad_char]\n",
    "    # rep[letter_index+1][0][pad_pos] = 1\n",
    "    return rep\n",
    "\n",
    "def hindi_word_to_tensor_r(word, letter2index, device = 'cpu'):\n",
    "    gt_rep = torch.zeros([len(word), 1], dtype=torch.long).to(device)\n",
    "    for letter_index, letter in enumerate(word):\n",
    "        pos = letter2index[letter]\n",
    "        gt_rep[letter_index][0] = pos\n",
    "    # gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
    "    return gt_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of6ZpHy1G4Ek"
   },
   "source": [
    "changing director to the proper folder where the data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648216676159,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "c2EErUA5SOvZ",
    "outputId": "4a046279-afcb-4351-c48e-3ecbc33eddd9"
   },
   "outputs": [],
   "source": [
    "# cd drive/MyDrive/\"Machine Transliteration\"/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMpW9Nk3H1LM"
   },
   "source": [
    "Following is the dataloader class being used for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648216676565,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "4IyWyXfwR8bO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TransliterationDataLoader(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
    "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
    "        random.shuffle(self.shuffle_indices)\n",
    "        self.shuffle_start_index = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eng_words)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.eng_words[idx], self.hindi_words[idx]\n",
    "    \n",
    "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
    "        trainData=pd.read_xml(filename)\n",
    "        trainData['SourceName']=trainData['SourceName'].apply(lambda x: cleanEnglishVocab(x))\n",
    "        trainData['TargetName']=trainData['TargetName'].apply(lambda x: cleanHindiVocab(x))\n",
    "        lang1_words = []\n",
    "        lang2_words = []\n",
    "        for i, (wordlist1, wordlist2) in enumerate(zip(trainData['SourceName'].tolist(), trainData['TargetName'].tolist())):\n",
    "            # Skip noisy data\n",
    "            if len(wordlist1) != len(wordlist2):\n",
    "                print('Skipping: ', wordlist1, ' - ', wordlist2)\n",
    "                continue\n",
    "            lang1_words.extend(wordlist1)\n",
    "            lang2_words.extend(wordlist2)\n",
    "\n",
    "        return lang1_words, lang2_words\n",
    "    \n",
    "    def get_random_sample(self):\n",
    "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
    "    \n",
    "    def get_batch_from_array(self, batch_size, array):\n",
    "        end = self.shuffle_start_index + batch_size\n",
    "        batch = []\n",
    "        if end >= len(self.eng_words):\n",
    "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
    "            end = len(self.eng_words)\n",
    "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
    "    \n",
    "    def get_batch(self, batch_size, postprocess = True):\n",
    "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
    "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
    "        self.shuffle_start_index += batch_size + 1\n",
    "        \n",
    "        # Reshuffle if 1 epoch is complete\n",
    "        if self.shuffle_start_index >= len(self.eng_words):\n",
    "            random.shuffle(self.shuffle_indices)\n",
    "            self.shuffle_start_index = 0\n",
    "            \n",
    "        return eng_batch, hindi_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==1.3.0 in /home/rxlogix/.local/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/rxlogix/.local/lib/python3.8/site-packages (from pandas==1.3.0) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/rxlogix/.local/lib/python3.8/site-packages (from pandas==1.3.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/rxlogix/.local/lib/python3.8/site-packages (from pandas==1.3.0) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/rxlogix/.local/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.0) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for pybind11: [Errno 2] No such file or directory: '/home/rxlogix/.local/lib/python3.8/site-packages/pybind11-2.9.0.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas==1.3.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1774,
     "status": "ok",
     "timestamp": 1648216678795,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "7phedO7lUh5G",
    "outputId": "55dcadcd-7462-40a1-fd8c-062933ce69d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping:  ['AUSTRALIAN', 'NATIONAL', 'UNIVERSITY']  -  ['ऑस्ट्रेलियननेशनल', 'यूनिवर्सिटी']\n",
      "Skipping:  ['AZAMNAGAR', 'ROAD']  -  ['आज़मनगर']\n",
      "Skipping:  ['BAL', 'KRISHNA']  -  ['बालकृष्णा']\n",
      "Skipping:  ['BARHARWA', 'JUNCTION']  -  ['बरहरवा']\n",
      "Skipping:  ['CAPE', 'TOWN']  -  ['केपटाउन']\n",
      "Skipping:  ['COLOURPLUS', 'FASHIONS']  -  ['कलर', 'प्लस', 'फ़ैशन्स']\n",
      "Skipping:  ['DIBANG', 'VALLEY']  -  ['दिबंगवैली']\n",
      "Skipping:  ['ENVOY', 'COMMUNICATIONS', 'GROUP']  -  ['एन्वॉय', 'कम्युनिकेशंस']\n",
      "Skipping:  ['FAKHRUN', 'NISA']  -  ['फखरुन्निसा']\n",
      "Skipping:  ['JAHAN', 'AARA']  -  ['जहाँआरा']\n",
      "Skipping:  ['KARA', 'KUM']  -  ['काराकुम']\n",
      "Skipping:  ['KELVINGROVE', 'ART', 'GALLERY', 'AND', 'MUSEUM']  -  ['केल्विनग्रोव', 'आर्ट', 'एण्ड', 'म्युज़ियम']\n",
      "Skipping:  ['KING', 'EDWARD', 'VII']  -  ['किंग', 'एडवर्ड']\n",
      "Skipping:  ['LONDONHEATHROW']  -  ['लंदन', 'हीथ्रो']\n",
      "Skipping:  ['MASS', 'MUTUAL', 'LIFE']  -  ['मास', 'म्युच्युअल', 'लाइफ़', 'इंश्योरेंस']\n",
      "Skipping:  ['MAUNA', 'LOA']  -  ['मौनालोआ']\n",
      "Skipping:  ['NAVABHARAT', 'FERRO', 'ALLOYS']  -  ['नव', 'भारत', 'फ़ैरो', 'अलॉय']\n",
      "Skipping:  ['NETAJI', 'SUBHASH', 'CHANDRA', 'BOSE']  -  ['नेताजी', 'सुभाषचंद्र', 'बोस']\n",
      "Skipping:  ['NEW', 'ZEALAND']  -  ['न्यूज़ीलैंड']\n",
      "Skipping:  ['NEWFOUNDLAND']  -  ['न्यू', 'फाउंडलैंड']\n",
      "Skipping:  ['OMKARNATH', 'THAKUR']  -  ['ओंकार', 'नाथ', 'ठाकुर']\n",
      "Skipping:  ['OPENTV']  -  ['ओपन', 'टीवी']\n",
      "Skipping:  ['ORDER', 'OF', 'VASA']  -  ['ऑडर', 'ऑफ़', 'द', 'वासा']\n",
      "Skipping:  ['PARIS', 'CHARLES', 'DE', 'GAULLE']  -  ['पेरिस', 'रॉसे', 'चार्ल्स', 'डे', 'ग्यूले']\n",
      "Skipping:  ['PARKWAY', 'APOSTOLIC']  -  ['पार्क', 'वे', 'अपोस्टोलिक']\n",
      "Skipping:  ['RAMA', 'LINGESHWARA']  -  ['रामालिंगेश्वर']\n",
      "Skipping:  ['RAMCOIND']  -  ['राम्को', 'इंड']\n",
      "Skipping:  ['REDIFFCOM', 'INDIA', 'LIMITED']  -  ['रेडिफ़', 'डॉट', 'कॉम', 'इंडिया', 'लिमिटेड']\n",
      "Skipping:  ['RETALIX']  -  ['रेटालिक्स', 'लि']\n",
      "Skipping:  ['ROCKBROOK', 'UNITED']  -  ['रॉकब्रुक', 'यूनाइटेड', 'मेथोडिस्ट']\n",
      "Skipping:  ['SEA', 'OF', 'THE', 'HEBRIDES']  -  ['सी', 'ऑफ', 'हरब्रिड्स']\n",
      "Skipping:  ['SOUTH', 'ARLINGTON', 'CHURCH', 'OF', 'CHRIST']  -  ['साउथ', 'अर्लिंग्टन']\n",
      "Skipping:  ['SRISAILAM']  -  ['श्री', 'शैलम']\n",
      "Skipping:  ['STATE', 'BNK', 'TR']  -  ['स्टेट', 'बैंक', 'ऑफ', 'त्रावणकोर']\n",
      "Skipping:  ['VAPARAISO', 'CHURCH', 'OF', 'CHRIST']  -  ['व्हापरासिओ']\n",
      "Skipping:  ['WALTER', 'SCOTT']  -  ['वॉल्टरस्कॉट']\n",
      "Skipping:  ['WAR', 'OF', 'THE', 'HOLY', 'LEAGUE']  -  ['वार', 'ऑफ', 'होली', 'लीग']\n",
      "Skipping:  ['WIND', 'RIVER']  -  ['विंडरिवर']\n"
     ]
    }
   ],
   "source": [
    "train_data = TransliterationDataLoader('NEWS2018_M-EnHi_trn.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1648216678795,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "6qThgnM_U2b2",
    "outputId": "92183f65-cd2a-466c-b6e4-dfc57e3b5578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size:\t 19115\n",
      "\n",
      "Sample data from train-set:\n",
      "GAJ - गज\n",
      "CHIZARIRA - चिज़ारिरा\n",
      "SULAKSHANA - सुलक्षणा\n",
      "BAALAMOHAN - बालमोहन\n",
      "SURDAAS - सूरदास\n",
      "KING - किंग\n",
      "MANZIL - मंज़िल\n",
      "GRAHAM - ग्रैहम\n",
      "PHANSI - फाँसी\n",
      "CULLMAN - कलमेन\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set Size:\\t\", len(train_data))\n",
    "\n",
    "print('\\nSample data from train-set:')\n",
    "for i in range(10):\n",
    "    eng, hindi = train_data.get_random_sample()\n",
    "    print(eng + ' - ' + hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648216678796,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "ytVIRV5OVLTA",
    "outputId": "59123377-18b7-4584-f832-87fea222506a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GURJEET tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "eng, hindi = train_data.get_random_sample()\n",
    "eng_rep = eng_word_to_tensor(eng, eng_alpha2index)\n",
    "print(eng, eng_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648216678796,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "cbM2wyqTVUjU",
    "outputId": "e7281f0a-ce39-4a8d-9e87-015825ebe7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "गुरजीत tensor([[24],\n",
      "        [66],\n",
      "        [49],\n",
      "        [29],\n",
      "        [65],\n",
      "        [37],\n",
      "        [ 0]])\n"
     ]
    }
   ],
   "source": [
    "hindi_gt = hindi_word_to_tensor(hindi, hindi_alpha2index)\n",
    "print(hindi, hindi_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648216678797,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "9WLHBoxwO0YP"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# all_letters=hindi_alpha2index\n",
    "# n_letters=129\n",
    "# # Find letter index from all_letters, e.g. \"a\" = 0\n",
    "# class letter_to_index(object):\n",
    "#   def __init__(self, all_letters,n_letters):\n",
    "#     self.all_letters=all_letters\n",
    "#     self.n_letters=n_letters\n",
    "#     self.pad_char = '-PAD-'\n",
    "\n",
    "#   def letterToIndex(self,letter):\n",
    "#       return self.all_letters[letter]\n",
    "\n",
    "#   # Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "#   def letterToTensor(self,letter):\n",
    "#       tensor = torch.zeros(1, self.n_letters)\n",
    "#       tensor[0][self.letterToIndex(letter)] = 1\n",
    "#       return tensor\n",
    "\n",
    "#   # Turn a line into a <line_length x 1 x n_letters>,\n",
    "#   # or an array of one-hot letter vectors\n",
    "#   def lineToTensor(self,line):\n",
    "#       tensor = torch.zeros(30, 1, self.n_letters)\n",
    "#       for li, letter in enumerate(line):\n",
    "#           tensor[li][0][self.letterToIndex(letter)] = 1\n",
    "#       for i in range(len(line),30,1):\n",
    "#         tensor[i][0][self.letterToIndex(self.pad_char)]=1 \n",
    "#       return tensor\n",
    "\n",
    "# ltiobj=letter_to_index(hindi_alpha2index,129)\n",
    "# print(ltiobj.letterToTensor('म'))\n",
    "# print(len('परशुराम'))\n",
    "\n",
    "# print(ltiobj.lineToTensor('परशुराम')[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648216679491,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "B3YQ3ODHR9w5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def eng_word_to_tensor(word, letter2index, device = 'cpu'):\n",
    "#   ltiobj=letter_to_index(letter2index,30)\n",
    "#   rep=ltiobj.lineToTensor(word)\n",
    "#   return rep\n",
    "\n",
    "# def hindi_word_to_tensor(word, letter2index, device = 'cpu'):\n",
    "#     gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
    "#     for letter_index, letter in enumerate(word):\n",
    "#         pos = letter2index[letter]\n",
    "#         gt_rep[letter_index][0] = pos\n",
    "#     gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
    "#     return gt_rep\n",
    "\n",
    "# # def hindi_word_to_tensor(word, letter2index, device = 'cpu'):\n",
    "# #   ltiobj=letter_to_index(letter2index,129)\n",
    "# #   rep=ltiobj.lineToTensor(word)\n",
    "# #   return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648216679492,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "MzcfghfI51Bu"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset,DataLoader\n",
    "# class TransliterationDataset(Dataset):\n",
    "\n",
    "#   def __init__(self,x,y):\n",
    "#     # x=train_df.iloc[:,1].values\n",
    "#     # y=train_df.iloc[:,2].values\n",
    "#     self.x_train=x\n",
    "#     self.y_train=y\n",
    "\n",
    "#   def __len__(self):\n",
    "#     return len(self.y_train)\n",
    "  \n",
    "#   def __getitem__(self,idx):\n",
    "#     X = eng_word_to_tensor(self.x_train[idx], eng_alpha2index)\n",
    "#     y = hindi_word_to_tensor(self.y_train[idx], hindi_alpha2index)\n",
    "#     return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648216680565,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "ocoFZSRBdY_O"
   },
   "outputs": [],
   "source": [
    "# len(eng_alpha2index)\n",
    "# #eng_word_to_tensor('PARSHURAM',eng_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1648216680566,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "Z9hCfqRXeLHG"
   },
   "outputs": [],
   "source": [
    "# len(hindi_alpha2index)\n",
    "# hindi_word_to_tensor('परशुराम',hindi_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648216681143,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "dFm91ikJ3Ein"
   },
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 30\n",
    "# class AttnDecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "#         super(AttnDecoderRNN, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.output_size = output_size\n",
    "#         self.dropout_p = dropout_p\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#         self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "#         self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "#         self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "#         self.dropout = nn.Dropout(self.dropout_p)\n",
    "#         self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "#         self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "#     def forward(self, input, hidden, encoder_outputs):\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "#         embedded = self.dropout(embedded)\n",
    "\n",
    "#         attn_weights = F.softmax(\n",
    "#             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "#         output = F.relu(output)\n",
    "#         output, hidden = self.gru(output, hidden)\n",
    "\n",
    "#         output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "#         return output, hidden, attn_weights\n",
    "\n",
    "#     def initHidden(self):\n",
    "#         return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model i will be using for this assignment would be Encoder Decoder attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1648216681526,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "AGMl8uHBMRUf"
   },
   "outputs": [],
   "source": [
    "MAX_OUTPUT_CHARS=30\n",
    "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
    "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
    "        \n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        \n",
    "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size, 1)\n",
    "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
    "        \n",
    "        # encoder\n",
    "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
    "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Encoder output', encoder_outputs.shape)\n",
    "        \n",
    "        # decoder\n",
    "        decoder_state = hidden\n",
    "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
    "        \n",
    "        outputs = []\n",
    "        U = self.U(encoder_outputs)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Decoder state', decoder_state.shape)\n",
    "            print('Decoder intermediate input', decoder_input.shape)\n",
    "            print('U * Encoder output', U.shape)\n",
    "        \n",
    "        for i in range(max_output_chars):\n",
    "            \n",
    "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
    "            V = self.attn(torch.tanh(U + W))\n",
    "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
    "            \n",
    "            if self.verbose:\n",
    "                print('W * Decoder state', W.shape)\n",
    "                print('V', V.shape)\n",
    "                print('Attn', attn_weights.shape)\n",
    "            \n",
    "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "            \n",
    "            embedding = self.out2hidden(decoder_input)\n",
    "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Attn LC', attn_applied.shape)\n",
    "                print('Decoder input', decoder_input.shape)\n",
    "                \n",
    "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder intermediate output', out.shape)\n",
    "                \n",
    "            out = self.h2o(decoder_state)\n",
    "            out = self.softmax(out)\n",
    "            outputs.append(out.view(1, -1))\n",
    "            \n",
    "            if self.verbose:\n",
    "                print('Decoder output', out.shape)\n",
    "                self.verbose = False\n",
    "            \n",
    "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
    "            if not ground_truth is None:\n",
    "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
    "            one_hot = torch.zeros(out.shape, device=device)\n",
    "            one_hot.scatter_(2, max_idx, 1) \n",
    "            \n",
    "            decoder_input = one_hot.detach()\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1648216682494,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "QoqdW2iHDadb"
   },
   "outputs": [],
   "source": [
    "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1648216685417,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "JtwGfsrNUOji",
    "outputId": "c8338610-1377-4717-d1f9-fc8aa347c6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_alpha2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 662,
     "status": "ok",
     "timestamp": 1648216687599,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "63TWhmvpeN0l",
    "outputId": "cc140333-efd7-42b7-bb3f-22ef465544e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output torch.Size([6, 256])\n",
      "Decoder state torch.Size([1, 1, 256])\n",
      "Decoder intermediate input torch.Size([1, 1, 129])\n",
      "U * Encoder output torch.Size([6, 256])\n",
      "W * Decoder state torch.Size([6, 256])\n",
      "V torch.Size([6, 1])\n",
      "Attn torch.Size([1, 6])\n",
      "Attn LC torch.Size([1, 1, 256])\n",
      "Decoder input torch.Size([1, 1, 512])\n",
      "Decoder intermediate output torch.Size([1, 1, 256])\n",
      "Decoder output torch.Size([1, 1, 129])\n"
     ]
    }
   ],
   "source": [
    "out=net_attn(eng_word_to_tensor('INDIA',eng_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648216688910,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "fMYqbwusYSXs",
    "outputId": "0e7667da-7624-4565-936f-d7ed9733afd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "torch.Size([1, 129]) भ\n",
      "torch.Size([1, 129]) भ\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n",
      "torch.Size([1, 129]) श\n"
     ]
    }
   ],
   "source": [
    "print(len(out))\n",
    "for i in range(len(out)):\n",
    "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAaLLCg4L3L3"
   },
   "source": [
    "Utilities methods for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1648216692985,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "XycdtIFYgZKF"
   },
   "outputs": [],
   "source": [
    "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        input = eng_word_to_tensor(eng_batch[i], eng_alpha2index, device)\n",
    "        gt = hindi_word_to_tensor(hindi_batch[i], hindi_alpha2index, device)\n",
    "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
    "        \n",
    "        for index, output in enumerate(outputs):\n",
    "            loss = criterion(output, gt[index]) / batch_size\n",
    "            loss.backward(retain_graph = True)\n",
    "            total_loss += loss\n",
    "        \n",
    "    opt.step()\n",
    "    return total_loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_r(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
    "    \n",
    "    net.train().to(device)\n",
    "    opt.zero_grad()\n",
    "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        input = eng_word_to_tensor_r(eng_batch[i], eng_alpha2index_r, device)\n",
    "        gt = hindi_word_to_tensor_r(hindi_batch[i], hindi_alpha2index_r, device)\n",
    "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
    "        \n",
    "        for index, output in enumerate(outputs):\n",
    "            loss = criterion(output, gt[index]) / batch_size\n",
    "            loss.backward(retain_graph = True)\n",
    "            total_loss += loss\n",
    "        \n",
    "    opt.step()\n",
    "    return total_loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup_r(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss(ignore_index = -1)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    teacher_force_upto = n_batches//3\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    prev_loss=0.5\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch_r(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            if loss_arr[i]<prev_loss:\n",
    "              prev_loss=loss_arr[i]\n",
    "              torch.save(net, 'model_best_6.pt')\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    \n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648216694905,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "vZTuCaW4g5Ia"
   },
   "outputs": [],
   "source": [
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    criterion = nn.NLLLoss(ignore_index = -1)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    teacher_force_upto = n_batches//3\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    prev_loss=0.5\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Loss', loss_arr[i])\n",
    "            if loss_arr[i]<prev_loss:\n",
    "              prev_loss=loss_arr[i]\n",
    "              torch.save(net, 'model_best_6.pt')\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "            \n",
    "    \n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648216696403,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "Jq4ubmjaiO6Y"
   },
   "outputs": [],
   "source": [
    "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_att_r = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index_r), 256, len(hindi_alpha2index_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is for model training with and without padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_history = train_setup_r(net_att_r, lr=0.002, n_batches=5000, batch_size = 64, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "RtBMS4cRiSxg",
    "outputId": "29a4a102-6eea-40e3-b1b2-664ab3fd27d3"
   },
   "outputs": [],
   "source": [
    "# loss_history = train_setup(net_att, lr=0.002, n_batches=10000, batch_size = 64, display_freq=10, device = device_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infrence from Model_trained_without_padding and Model_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "sNX1UxybMSHm"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model_without_padding = torch.load('model_best_1.pt',map_location=device)\n",
    "model_with_padding = torch.load('model_best_6.pt',map_location=device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "GchqT7pcMZ6M"
   },
   "outputs": [],
   "source": [
    "def test(model, word, device = 'cpu'):\n",
    "    net_attn = model.eval().to(device)\n",
    "    outputs=net_attn(eng_word_to_tensor(word,eng_alpha2index),30)\n",
    "    hindi_output = ''\n",
    "#     print(len(outputs))\n",
    "    for out in outputs:\n",
    "        val, indices = out.topk(1)\n",
    "        index = indices.tolist()[0][0]\n",
    "        if index == 0:\n",
    "            break\n",
    "        hindi_char = hindi_alphabets[index-1]\n",
    "        hindi_output += hindi_char\n",
    "    print(word + ' - ' + hindi_output)\n",
    "    return hindi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "BeBReAow9Oxt"
   },
   "outputs": [],
   "source": [
    "def test_r(model, word, device = 'cpu'):\n",
    "    net_attn = model.eval().to(device)\n",
    "    outputs=net_attn(eng_word_to_tensor_r(word,eng_alpha2index_r),30)\n",
    "    hindi_output = ''\n",
    "#     print(len(outputs))\n",
    "    prev_index=['0','0']\n",
    "    for out in outputs:\n",
    "        val, indices = out.topk(1)\n",
    "        index = indices.tolist()[0][0]\n",
    "#         print('type is ',type(prev_index))\n",
    "        if index==int(prev_index[0]) or index==int(prev_index[1]) :\n",
    "#           print(val.tolist()[0][0])\n",
    "          break\n",
    "        else:\n",
    "          del prev_index[0]\n",
    "          prev_index.append(index)\n",
    "#           print(index)\n",
    "#           print(val.tolist()[0][0])\n",
    "        hindi_char = hindi_alphabets[index]\n",
    "        hindi_output += hindi_char\n",
    "\n",
    "    print(word + ' - ' + hindi_output)\n",
    "    return hindi_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648196568294,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "fl3GmO4rM_TU",
    "outputId": "4208822e-11b5-44aa-9351-dc1c26b374dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVNAGRI - देवनार्\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_r(model_without_padding, 'DEVNAGRI', device = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVNAGRI - देवनग्री\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test(model_with_padding, 'DEVNAGRI', device = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1648050357743,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "PcJ8wRXGOFWB",
    "outputId": "9d36896f-f46f-475d-f1ed-24c213be3819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping:  ['STATS', 'CHIPPAC']  -  ['स्टेट्सचिपपैक']\n"
     ]
    }
   ],
   "source": [
    "test_data = TransliterationDataLoader('NEWS2018_M-EnHi_dev.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "E2j_09fwN62m"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(net, device = 'cpu'):\n",
    "    net = net.eval().to(device)\n",
    "    predictions = []\n",
    "    accuracy = 0\n",
    "    for i in range(len(test_data)):\n",
    "        eng, hindi = test_data[i]\n",
    "        gt = hindi_word_to_tensor(hindi, hindi_alpha2index, device)\n",
    "        outputs=net(eng_word_to_tensor(eng,eng_alpha2index),gt.shape[0],device)\n",
    "#         print(gt.shape[0])\n",
    "        # outputs = infer(net, eng, gt.shape[0], device)\n",
    "        correct = 0\n",
    "        hindi_output=''\n",
    "        for index, out in enumerate(outputs):\n",
    "            val, indices = out.topk(1)\n",
    "            hindi_pos = indices.tolist()[0]\n",
    "#             print(hindi_pos[0])\n",
    "            if hindi_pos[0]==0:\n",
    "                break\n",
    "            hindi_char = hindi_alphabets[hindi_pos[0]-1]\n",
    "            hindi_output += hindi_char\n",
    "#             print(eng+' - '+hindi_output)\n",
    "            \n",
    "            if hindi_pos[0] == gt[index][0]:\n",
    "                correct += 1\n",
    "        \n",
    "        accuracy += correct/gt.shape[0]\n",
    "    accuracy /= len(test_data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25854,
     "status": "ok",
     "timestamp": 1648050386411,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "k7ysCuEHRLhu",
    "outputId": "10ff1af1-54a2-4bff-f9aa-56ce502bde5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444283968443626"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(model_with_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vkCQvjJL-Zl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1647950192154,
     "user": {
      "displayName": "RAKESH KUMAR SHARMA",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07423953061185665068"
     },
     "user_tz": -330
    },
    "id": "OMAdN5_Q9n3y",
    "outputId": "798754cf-2f51-44b3-d61f-ba98f498153e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 30, 1, 30]) torch.Size([100, 30, 1, 129])\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# for i, (data, labels) in enumerate(train_loader):\n",
    "#   print(data.shape, labels.shape)\n",
    "#   print(data[1],labels[1])\n",
    "#   break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbjkUTMlBwLU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNcBKnwV5ndH6492WzDZTC6",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
